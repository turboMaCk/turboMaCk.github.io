---
title: Value Space Decoding for Aeson
subtitle: TODO
description: TODO
tags: haskell, web
---

I've learned to like the way JSON decoding works in Elm.
Or maybe more generally I see some advantages in parsing JSONs
with combinators. In some situations I would very much prefer
combinators over type class instances used by [[https://hackage.haskell.org/package/aeson][Aeson]]. Here is why and how.

* Conceptual Model of Type Classes

I know this statement might be a bit controversial given how popular fancy types
and type level programming in Haskell is. Anyway I'm not trying to necessary make
case against advanced type system features in general. Let me explain.

Type classes are mechanism to define type as being member of some number of classes.
Or other way around define class of data types which can have multiple members.
The important aspect though is that given specific type and specific type there is exactly
one way in which data type can be made instance of the class.
Even with type classes like ~Applicative~ "suffer" from this limitation.
~[a]~ data type for instance has 2 completely valid, but different, implementations
of ~Applicative~ instance. I don't think this is problematic in practice as much though and
I do believe type classes good concept to have in a language. Edward Kmett has
[[https://www.youtube.com/watch?v=hIZxTQP1ifo][a very good talk which goes deeper into this]].

I hope I've managed to establish that with classes like ~FromJSON~ we're essentially closing
the JSON parsing over types (which are member of this class). I think this in many cases is not a good model of the domain.
Much better model is to expect that there is a number of JSON values we consume
and number of data types which gets decoded from these.
It's fair to assume the same data type can be decoded from different JSONs structures
(problematic with type classes) as it is
to assume the same JSON structure can be decoded to different data types (no problem with classes which are closed over data, not over JSON).

Currently it's a common practice to define type wrappers around existing data types
just to make it possible to define "another" instance of ~FromJSON~ around the type.
While this solution works I personally don't find it satisfying.
To me all these types are unnecessary noise. I don't like to have types
which are, in my opinion at least, not important in the conceptual model of domain at all.

I would simply like to be able to extract same data type from different JSON structures without
a need of defining extra types.

* Solution

What I would in fact like to have is not a complete replacement for type classes.
There are in fact cases where there it make sense to have a single definition
of mapping between JSON and data types. What I would like to have is mix of both world.
I still want to be able to define ~FromJSON~ instance but I also want an option to define
"decoders" not as in Instance but as a value.

What I mean I that is to be able to do something like this

#+BEGIN_SRC haskell
data Person = Person {
      name :: Text
    , age  :: Int
    } deriving (Generic, Show)

instance FromJSON Person

decodeEmbededPerson :: [Text] -> ByteString -> Maybe Person
decodeEmbededPerson path json =
    ACD.decode (ACD.at path ACD.auto) json
#+END_SRC

which can be used to extract decode ~Person~ embedded in
any JSON structure like:

#+BEGIN_SRC shell
>>> decodeEmbededPerson ["data", "person"] "{\"data\": {\"person\":{\"name\":\"Joe\",\"age\":12}}}"
Just (Person {name = "Joe", age = 12})
#+END_SRC

Or to be able to define anonymous product decoder (to tuples):

#+BEGIN_SRC haskell
type Token = Text

decodePersonWithToken :: ByteString -> Maybe (Token, Person)
decodePersonWithToken json =
    ACD.decode decoder json
    where decoder =
            (,) <$> ACD.field "token" ACD.auto
                <*> ACD.field "person" ACD.auto
#+END_SRC

which works as following:

#+BEGIN_SRC shell
decodePersonWithToken "{\"person\":{\"name\":\"Joe\",\"age\":12}, \"token\": \"foo\"}"
Just ("foo",Person {name = "Joe", age = 12})
#+END_SRC

* Implementation

So the idea is to be able to define ~Decoder a~ type which is essentially just ~parseJSON~
method from ~FromJSON~ class. Since we want to make all of this work with Aeson type classes
without introducing much overhead we simply just wrap it to ~newtype~:

#+BEGIN_SRC haskell
newtype Decoder a =
  Decoder (Value -> Parser a)
#+END_SRC

The simplest constructor of this type is for types which are member of ~FromJSON~ class:

#+BEGIN_SRC haskell
auto :: FromJSON a => Decoder a
auto = Decoder parseJSON
#+END_SRC

I don't want to spent much time defining other constructors as this alone provides
enough but as an example this we can easily define constructor which turns any ~Decoder a~
to ~Decoder [a]~:

#+BEGIN_SRC haskell
list :: Decoder a -> Decoder [a]
list (Decoder d) = Decoder $ listParser d
#+END_SRC

where [[https://hackage.haskell.org/package/aeson-1.4.6.0/docs/Data-Aeson-Types.html#v:listParser][~listParser~]] is a function provided by Aeson itself.

To make ~Decoder~ useful we're going to define instances of Functor, Applicative and Monad
which should be enough for providing most important functionality.

#+BEGIN_SRC haskell
instance Functor Decoder where
  fmap f (Decoder d) = Decoder $ fmap f . d

instance Applicative Decoder where
  pure val = Decoder $ \_ -> pure val
  (Decoder f') <*> (Decoder d) = Decoder $
    \val ->
        (\f -> fmap f (d val)) =<< f' val

instance Monad Decoder where
  (Decoder a) >>= f = Decoder $
    \val -> case parse a val of
      Success v -> let (Decoder res) = f v
                   in res val
      _ -> unexpected val
#+END_SRC

And finally some combinators specific for JSON:

For working with JSON objects we also need a function then can extract value from
JSON filed. Then we can even define another function which for drilling a few levels
deep into JSON:

#+BEGIN_SRC haskell
field :: Text -> Decoder a -> Decoder a
field t (Decoder d) = Decoder $
  \val -> case val of
    Object v -> d =<< v .: t
    _        -> typeMismatch "Object" val

at :: [Text] -> Decoder a -> Decoder a
at path d =
  foldr field d path
#+END_SRC

Once again this is using functions already provided by Aeson.

Last step is define new [[https://hackage.haskell.org/package/aeson-1.4.6.0/docs/Data-Aeson.html#v:decode][decode]] which will work with ~Decoder~.

#+BEGIN_SRC haskell
decode :: Decoder a -> LB.ByteString -> Maybe a
decode (Decoder d) =
  Parser.decodeWith ParserI.jsonEOF (parse d)
#+END_SRC

Once again all functions used here are provided by Aeson. ~LB~ is a lazy version of ~ByteString~.

And this is all we need to make examples from section above working.

* Elm Style Decoding

It's possible of course possible to use this ~Decoder~ type exclusively.
This makes writing Aeson decoders feel like using [[https://package.elm-lang.org/packages/elm/json/latest/Json-Decode][elm/json]]
(together with [[https://package.elm-lang.org/packages/elm-community/json-extra/latest/][elm-community/json-extra]] for "applicative" ~andMap~)

#+BEGIN_SRC haskell
data Person = Person {
      name :: Text
    , age  :: Int
    } deriving (Show)

personDecoder :: Decoder Person
personDecoder =
    Person
        <$> field "name" auto
        <*> field "age" auto
#+END_SRC

* Additional Resources

Full implementation of this Idea can be found in [[https://github.com/turboMaCk/aeson-combinators][this GitHub repository]].
Feel free to provide any feedback about this idea including criticism.
Be aware that this is not published and is still missing some important bits.

[[https://hackage.haskell.org/package/waargonaut][Waargonaut]] package is Aeson alternative which has API similar to what I've described here
if you want to avoid whole Aeson.

Also while writing this post I've discovered that Chris Martin had a similar idea
implemented in [[https://hackage.haskell.org/package/aeson-decode-0.1.0.0/docs/AesonDecode.html][aeson-decode]] package but the actual implementation uses ~Value -> Maybe a~
function similar to [[https://twitter.com/turbo_MaCk/status/1227247541336641536][my original prototype]]. I believe that implementation proposed in
this article is better.
